{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NuK_BQmNAXc7"
      },
      "outputs": [],
      "source": [
        "import pytest\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.metrics import r2_score\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Initial configuration"
      ],
      "metadata": {
        "id": "9zb9jmvHIl8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLLinearModel:\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      alpha:float,\n",
        "      l1_ratio:float,\n",
        "      model_name=\"\"\n",
        "      ):\n",
        "\n",
        "    # Store params\n",
        "    self.alpha = alpha\n",
        "    self.l1_ratio = l1_ratio\n",
        "    self.model_name = model_name\n",
        "\n",
        "    # Initializate parameters\n",
        "    self.model_reg = None\n",
        "\n",
        "  def train_model(self, X_train:np.ndarray, y_train:np.ndarray):\n",
        "    self.model_reg = ElasticNet(random_state=0, alpha=self.alpha, l1_ratio=self.l1_ratio)\n",
        "    self.model_reg.fit(X_train, y_train)\n",
        "    print(self.model_reg.coef_)\n",
        "    print(self.model_reg.intercept_)\n",
        "\n",
        "  def predict_model(self, X_test:np.ndarray):\n",
        "    y_pred = self.model_reg.predict(X_test)\n",
        "    return y_pred\n",
        "\n",
        "  def evaluate_model(self, X_test:np.ndarray, y_test:np.ndarray):\n",
        "    y_pred = self.predict_model(X_test)\n",
        "    return {'r2_score': r2_score(y_test, y_pred)}"
      ],
      "metadata": {
        "id": "xgh9uc_UGsGd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "n_features = 4\n",
        "X_train, y_train = make_regression(n_features=n_features, random_state=0)\n",
        "X_test, y_test = make_regression(n_features=n_features, random_state=0)"
      ],
      "metadata": {
        "id": "WHuskzjJIo6L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try class\n",
        "model_reg =  MLLinearModel(alpha=1.0, l1_ratio=0.5,model_name=\"prueba\")\n",
        "model_reg.train_model(X_train=X_train, y_train=y_train)\n",
        "model_reg.evaluate_model(X_test=X_test, y_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyKqeLdsIo8a",
        "outputId": "2aacdbd2-8b43-46a1-d41d-fa01a97a8c6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17.01756265 25.92033077 42.98727128 57.7739761 ]\n",
            "-0.7022844637724632\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'r2_score': 0.8905284935984247}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.1. Logging\n",
        "\n",
        "Source:\n",
        "* https://realpython.com/python-logging/"
      ],
      "metadata": {
        "id": "BZGesKhL4IAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logging_example.py\n",
        "\n",
        "import logging\n",
        "\n",
        "# Create a custom logger\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Create handlers\n",
        "c_handler = logging.StreamHandler()\n",
        "f_handler = logging.FileHandler('file.log')\n",
        "c_handler.setLevel(logging.WARNING)\n",
        "f_handler.setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "# Create formatters and add it to handlers\n",
        "c_format = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
        "f_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "#f_format = logging.Formatter('[%(asctime)s] p%(process)s {%(pathname)s:%(lineno)d} %(levelname)s - %(message)s','%m-%d %H:%M:%S')\n",
        "\n",
        "c_handler.setFormatter(c_format)\n",
        "f_handler.setFormatter(f_format)\n",
        "\n",
        "# Add handlers to the logger\n",
        "logger.addHandler(c_handler)\n",
        "logger.addHandler(f_handler)\n",
        "\n",
        "logger.warning('This is a warning')\n",
        "logger.error('This is an error')\n",
        "logger.debug('This is a debug message')\n",
        "logger.info('This is an info message')\n",
        "logger.warning('This is a warning message')\n",
        "logger.error('This is an error message')\n",
        "logger.critical('This is a critical message')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYTuO4zB6BrA",
        "outputId": "9e1eb7d6-874e-4481-ac0b-80b577f0fb33"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "WARNING:__main__:This is a warning\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "ERROR:__main__:This is an error\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "WARNING:__main__:This is a warning message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "ERROR:__main__:This is an error message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "CRITICAL:__main__:This is a critical message\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.critical('Prueba')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxrK4vJS4G_G",
        "outputId": "bae10a68-e387-4e2b-a580-9c0a8d672c68"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "CRITICAL:__main__:Prueba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging_example.py\n",
        "\n",
        "import logging\n",
        "\n",
        "# Create a custom logger\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Create handlers\n",
        "f_handler = logging.FileHandler('file_2.log')\n",
        "f_handler.setLevel(logging.ERROR)\n",
        "f_handler.setLevel(logging.DEBUG)\n",
        "\n",
        "# Create formatters and add it to handlers\n",
        "f_format = logging.Formatter('[%(asctime)s] p%(process)s {%(pathname)s:%(lineno)d} %(levelname)s - %(message)s','%m-%d %H:%M:%S')\n",
        "\n",
        "f_handler.setFormatter(f_format)\n",
        "\n",
        "# Add handlers to the logger\n",
        "logger.addHandler(f_handler)\n",
        "\n",
        "logger.warning('This is a warning')\n",
        "logger.error('This is an error')\n",
        "logger.debug('This is a debug message')\n",
        "logger.info('This is an info message')\n",
        "logger.warning('This is a warning message')\n",
        "logger.error('This is an error message')\n",
        "logger.critical('This is a critical message')\n",
        "logger.critical('Prueba')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Sl__ORl4HBw",
        "outputId": "9e9fefe4-9cb7-4c5e-b782-d63d2db43871"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "__main__ - WARNING - This is a warning\n",
            "WARNING:__main__:This is a warning\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "__main__ - ERROR - This is an error\n",
            "ERROR:__main__:This is an error\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "__main__ - WARNING - This is a warning message\n",
            "WARNING:__main__:This is a warning message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "__main__ - ERROR - This is an error message\n",
            "ERROR:__main__:This is an error message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "__main__ - CRITICAL - This is a critical message\n",
            "CRITICAL:__main__:This is a critical message\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "__main__ - CRITICAL - Prueba\n",
            "CRITICAL:__main__:Prueba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gAIL9e6M4mHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i4aJuVI54mJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwrxCt5M4mMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Unit Tests"
      ],
      "metadata": {
        "id": "wuPMTXLvAisD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Initial example"
      ],
      "metadata": {
        "id": "BQgAY10UJmpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLModel:\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      param1:float,\n",
        "      param2:float,\n",
        "      model_name:str\n",
        "      ):\n",
        "\n",
        "    # Store params\n",
        "    self.param1 = param1\n",
        "    self.param2 = param2\n",
        "    self.model_name = model_name\n",
        "\n",
        "  def train_model(self):\n",
        "    pass\n",
        "\n",
        "  def predict_model(self):\n",
        "    pass\n",
        "\n",
        "  def evaluate_model(self):\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "6k1CWx6fAh3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define several tests within a function, and evaluate them over different\n",
        "# configurations\n",
        "def test_answer(result_test):\n",
        "    assert result_test.param1 >= 0\n",
        "    assert result_test.param2 >= 0\n",
        "    assert type(result_test.param1) == float\n",
        "    assert type(result_test.param2) == float\n",
        "\n",
        "def test1():\n",
        "    return MLModel(param1=1.1, param2=1.2, model_name=\"prueba\")\n",
        "\n",
        "def test2():\n",
        "    return MLModel(param1=1.1, param2=-1, model_name=\"prueba\")\n",
        "\n",
        "# Test 1\n",
        "test_answer(result_test = test1())\n",
        "\n",
        "# Test 2\n",
        "test_answer(result_test = test2())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "EuXeni1BFN8P",
        "outputId": "9f95cd24-94f4-454d-b11c-1ec6b76ae626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d437937d67d6>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Test 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtest_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-d437937d67d6>\u001b[0m in \u001b[0;36mtest_answer\u001b[0;34m(result_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mresult_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mresult_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@pytest.fixture()\n",
        "def test1():\n",
        "    return MLModel(param1=1.1, param2=1.2, model_name=\"prueba\")\n",
        "\n",
        "def test_unit_create_model(test1):\n",
        "    #assert test1.model_name == \"prueba\"\n",
        "    assert test1.param1 >= 0\n",
        "    assert test1.param2 >= 0\n",
        "    assert test1.param1 == float\n",
        "    assert test1.param2 == float"
      ],
      "metadata": {
        "id": "6WcoFMXdAh6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_unit_create_model(test1)"
      ],
      "metadata": {
        "id": "MIlYEX4jAh8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLModel(param1=1.1, param2=1.2, model_name=\"prueba\").model_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZO6jeGq6Ah-7",
        "outputId": "999b363c-c458-4321-cf85-a12c418ea1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'prueba'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Another example\n",
        "Source:\n",
        "* https://github.com/miguelgfierro/pybase/blob/main/test/pytest_fixtures.py\n",
        "* https://docs.pytest.org/en/6.2.x/fixture.html"
      ],
      "metadata": {
        "id": "jRkjEFwOy7Nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data structures\n",
        "@pytest.fixture()\n",
        "def basic_structures():\n",
        "    data = {\n",
        "        \"int\": 5,\n",
        "        \"yes\": True,\n",
        "        \"no\": False,\n",
        "        \"float\": 0.5,\n",
        "        \"pi\": 3.141592653589793238462643383279,\n",
        "        \"string\": \"Name\",\n",
        "        \"none\": None,\n",
        "    }\n",
        "    return data\n",
        "\n",
        "@pytest.fixture()\n",
        "def complex_structures():\n",
        "    my_list = [1, 2, 3]\n",
        "    my_dict = {\"a\": 1, \"b\": 2}\n",
        "    return my_list, my_dict\n",
        "\n",
        "@pytest.fixture()\n",
        "def numeric_libs(complex_structures):\n",
        "    l, d = complex_structures\n",
        "    np_array = np.array(l)\n",
        "    df = pd.DataFrame(d, index=[0])\n",
        "    series = pd.Series(l)\n",
        "    return np_array, df, series"
      ],
      "metadata": {
        "id": "GzKDb8-IAiBT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tests\n",
        "def test_basic_structures(basic_structures):\n",
        "    assert basic_structures[\"int\"] == 5\n",
        "    assert basic_structures[\"yes\"] is True\n",
        "    assert basic_structures[\"no\"] is False\n",
        "    assert basic_structures[\"float\"] == 0.5\n",
        "    assert basic_structures[\"string\"] == \"Name\"\n",
        "    assert basic_structures[\"none\"] is None\n",
        "\n",
        "\n",
        "def test_comparing_numbers(basic_structures):\n",
        "    assert basic_structures[\"pi\"] == pytest.approx(3.1415926, 0.0000001)\n",
        "    assert basic_structures[\"pi\"] != pytest.approx(3.1415926, 0.00000001)\n",
        "    assert basic_structures[\"int\"] > 3\n",
        "    assert basic_structures[\"int\"] >= 5\n",
        "    assert basic_structures[\"int\"] < 10\n",
        "    assert basic_structures[\"int\"] <= 5\n",
        "\n",
        "\n",
        "def test_lists(complex_structures):\n",
        "    l = complex_structures[0]\n",
        "    assert l == [1, 2, 3]\n",
        "    assert Counter(l) == Counter([2, 1, 3])  # list have same elements\n",
        "    assert 1 in l\n",
        "    assert 5 not in l\n",
        "    assert all(x in l for x in [2, 3])  # sublist in list\n",
        "\n",
        "\n",
        "def test_dictionaries(complex_structures):\n",
        "    d = complex_structures[1]\n",
        "    assert d == {\"a\": 1, \"b\": 2}\n",
        "    assert \"a\" in d\n",
        "    assert d.items() <= {\"a\": 1, \"b\": 2, \"c\": 3}.items()  # subdict in dict\n",
        "    with pytest.raises(KeyError):\n",
        "        value = d[\"c\"]\n",
        "\n",
        "\n",
        "def test_pandas(numeric_libs):\n",
        "    _, df, series = numeric_libs\n",
        "    df_target = pd.DataFrame({\"a\": 1, \"b\": 2}, index=[0])\n",
        "    series_target = pd.Series([1, 2, 3])\n",
        "    pd.testing.assert_frame_equal(df, df_target)\n",
        "    pd.testing.assert_series_equal(series, series_target)\n",
        "\n",
        "\n",
        "def test_numpy(numeric_libs):\n",
        "    np_array = numeric_libs[0]\n",
        "    np_target = np.array([1, 2, 3])\n",
        "    np_target2 = np.array([0.9999, 2, 3])\n",
        "    assert np.all(np_array == np_target)\n",
        "    np.testing.assert_array_equal(np_array, np_target)  # same as before\n",
        "    np.testing.assert_array_almost_equal(np_array, np_target2, decimal=4)"
      ],
      "metadata": {
        "id": "IS-BvUNrAiD6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Smoke Tests"
      ],
      "metadata": {
        "id": "toSytWynC2hF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0NzGzU_a29AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCrFMiwp29Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Integration/Functional Tests"
      ],
      "metadata": {
        "id": "ef-pCo-bC4f6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fA0oxdgT29E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJ5lpwha29He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSxSlPaAC8eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Utility Test"
      ],
      "metadata": {
        "id": "U3Mo8Sy4C8_u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCajppiqC8hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bf59Sph7C8jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plooxSm-29J1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}