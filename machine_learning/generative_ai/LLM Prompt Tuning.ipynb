{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP04EEOHn06A5MYl/aoO5cl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Automatic Prompt Tuning"],"metadata":{"id":"eI1CGWiodjEt"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrDKtgiwdgPc","executionInfo":{"status":"ok","timestamp":1734086296016,"user_tz":-60,"elapsed":22789,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}},"outputId":"280daaba-6ff6-4cc9-89b8-547d6e4a96af"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","transformers 4.47.0 requires huggingface-hub<1.0,>=0.24.0, but you have huggingface-hub 0.23.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["%pip install -q huggingface-hub==0.23.2\n","%pip install -q transformers==4.47.0\n","%pip install -q datasets==2.19.1\n","%pip install -q sentence-transformers==2.7.0\n","%pip install -q optuna==3.6.1"]},{"cell_type":"markdown","source":["## 0. Setup"],"metadata":{"id":"hesSm5WhfWO7"}},{"cell_type":"code","source":["import os\n","import yaml\n","from google.colab import drive\n","from getpass import getpass\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1Gpdy5vfRuU","executionInfo":{"status":"ok","timestamp":1734086297802,"user_tz":-60,"elapsed":1790,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}},"outputId":"888ecb9b-305a-4d52-a47c-14ec601bbccd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Read YAML file\n","f_path = \"/content/drive/MyDrive/GitHub/python-codebase/machine_learning/private_keys.yml\"\n","with open(f_path, 'r') as stream:\n","    data_loaded = yaml.safe_load(stream)\n","os.environ['HF_API_TOKEN'] = data_loaded['HF_API_KEY']\n","os.environ['GITHUB_TOKEN'] = data_loaded['GITHUB_TOKEN']"],"metadata":{"id":"MBNQFG4rffNK","executionInfo":{"status":"ok","timestamp":1734086297802,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Set up token\n","from huggingface_hub import login\n","login(token=os.environ['HF_API_TOKEN'])"],"metadata":{"id":"0Dv4QgftffPp","executionInfo":{"status":"ok","timestamp":1734086298692,"user_tz":-60,"elapsed":892,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 1. Initial example"],"metadata":{"id":"K3cPpoNefY1q"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from sentence_transformers import SentenceTransformer, util\n","from datasets import load_dataset\n","from joblib import Parallel, delayed\n","from tqdm import tqdm"],"metadata":{"id":"Tr6YXw9vdiDE","executionInfo":{"status":"ok","timestamp":1734086322456,"user_tz":-60,"elapsed":23766,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Helper functions\n","def get_embedding(text):\n","    \"\"\"Generate sentence embeddings for a given text.\"\"\"\n","    return embedding_model.encode(text, convert_to_tensor=True)\n","\n","def compute_similarity(output, target):\n","    \"\"\"Compute cosine similarity between generated output and target text.\"\"\"\n","    output_embedding = get_embedding(output)\n","    target_embedding = get_embedding(target)\n","    return util.cos_sim(output_embedding, target_embedding).item()\n","\n","def generate_text(prompt, article):\n","    \"\"\"Generate text using the language model given a prompt and article.\"\"\"\n","    input_text = prompt + article\n","    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n","    outputs = lm.generate(**inputs, max_new_tokens=128, num_return_sequences=1, do_sample=True)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","def optimize_prompt(current_prompt, target, output, similarity):\n","    \"\"\"Optimize the prompt using another LLM.\"\"\"\n","    input_text = (\n","        f\"Current Prompt: {current_prompt}\\n\"\n","        f\"Target: {target}\\n\"\n","        f\"Generated Output: {output}\\n\"\n","        f\"Cosine Similarity: {similarity:.4f}\\n\"\n","        f\"Provide an improved prompt:\"\n","    )\n","    inputs = optimizer_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n","    outputs = optimizer_lm.generate(**inputs, max_new_tokens=128, num_return_sequences=1, do_sample=True)\n","    return optimizer_tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"MiZZigyRe2Z8","executionInfo":{"status":"ok","timestamp":1734086813444,"user_tz":-60,"elapsed":201,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Load the language model and tokenizer\n","#lm_model_name = \"EleutherAI/gpt-neo-125M\"\n","#lm_model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n","#lm_model_name = \"akjindal53244/Llama-3.1-Storm-8B\"\n","#lm_model_name = \"gpt2-medium\"\n","lm_model_name = \"distilgpt2\"\n","lm = AutoModelForCausalLM.from_pretrained(lm_model_name)\n","tokenizer = AutoTokenizer.from_pretrained(lm_model_name)\n","\n","# Load a pre-trained embedding model for similarity calculation\n","embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n","embedding_model = SentenceTransformer(embedding_model_name)\n","\n","# Load another LLM for prompt optimization\n","#optimizer_model_name = \"EleutherAI/gpt-neo-125M\"  # Replace with a suitable model for prompt optimization\n","#optimizer_model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n","#optimizer_model_name = \"gpt2-medium\"\n","optimizer_model_name = \"distilgpt2\"\n","optimizer_lm = AutoModelForCausalLM.from_pretrained(optimizer_model_name)\n","optimizer_tokenizer = AutoTokenizer.from_pretrained(optimizer_model_name)"],"metadata":{"id":"xiZPcOUediFc","executionInfo":{"status":"ok","timestamp":1734086595170,"user_tz":-60,"elapsed":4335,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Load an example dataset for text generation\n","dataset = load_dataset(\"xsum\", split=\"test[:15]\")  # A dataset with input and target texts\n","\n","# Base prompt to tune\n","base_prompt = \"Summarize the following article: \"\n","\n","# Hyperparameters for prompt tuning\n","num_iterations = 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FejUVAcxgrUi","executionInfo":{"status":"ok","timestamp":1734086599232,"user_tz":-60,"elapsed":1523,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}},"outputId":"bab2be50-72b5-4315-9233-a71fb7c173b5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Prepare dataset articles and targets\n","articles = dataset[\"document\"]  # Input texts for generation\n","targets = dataset[\"summary\"]  # Target texts to match\n","\n","dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2PSrsNhf5VK","executionInfo":{"status":"ok","timestamp":1734086600653,"user_tz":-60,"elapsed":230,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}},"outputId":"3912e108-13d5-4901-fee5-780021261808"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'document': 'Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\\nWorkers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\\nThe Welsh Government said more people than ever were getting help to address housing problems.\\nChanges to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\\nPrison Link Cymru, which helps people find accommodation after their release, said things were generally good for women because issues such as children or domestic violence were now considered.\\nHowever, the same could not be said for men, the charity said, because issues which often affect them, such as post traumatic stress disorder or drug dependency, were often viewed as less of a priority.\\nAndrew Stevens, who works in Welsh prisons trying to secure housing for prison leavers, said the need for accommodation was \"chronic\".\\n\"There\\'s a desperate need for it, finding suitable accommodation for those leaving prison there is just a lack of it everywhere,\" he said.\\n\"It could take six months to a year, without a lot of help they could be on the streets for six months.\\n\"When you think of the consequences of either being on the street, especially with the cold weather at the moment or you may have a roof over your head, sometimes there is only one choice.\"\\nMr Stevens believes building more one-bedroom flats could help ease the problem.\\n\"The average price is a hundred pounds a week to keep someone in a rented flat, prison is a lot more than that so I would imagine it would save the public purse quite a few pounds,\" he said.\\nOfficial figures show 830 one-bedroom properties were built in the year to March 2016, of an overall total of 6,900 new properties in Wales.\\nMarc, 50, who has been in and out of prison for the past 20 years for burglary offences, said he struggled to find accommodation each time he was released.\\nHe said he would ask himself: \"Where am I going to stay? Where am I going to live? Have I got somewhere where I can see my daughter.\"\\n\"You\\'re put out among the same sort of people doing the same sort of thing, and it\\'s difficult, it\\'s difficult to get away from it. It\\'s like every man for himself, there\\'s nothing.\"\\nMarc has now found stable accommodation with homeless charity Emmaus and said it had been life changing.\\n\"You feel safe, you got hot food, you\\'ve got company of people in similar situations to yourself but all dealing with different issues. It\\'s a constructive, helpful atmosphere,\" he said.\\nTom Clarke, chief executive of Emmaus South Wales, agreed there was not enough support available.\\n\"We do still see [people] homeless on the streets, so clearly they haven\\'t got accommodation and haven\\'t got provision,\" he said.\\n\"I think the key is connecting people with the services they need. I don\\'t delude myself that Emmaus can offer a one size fits all for everyone, we can\\'t.\\n\"But there must be other opportunities and given suitable encouragement I believe that can and should happen.\"\\nA Welsh Government spokesman said the national pathway for homeless services to children, young people and adults in the secure estate had prevented many people from losing their home whilst serving their prison sentence.\\nIt added there were already significant demands for one-bedroom flats across the public and private sector and it was providing 20,000 new affordable homes in the next five years.',\n"," 'summary': 'There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.',\n"," 'id': '38264402'}"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["### Parallelize with Joblib"],"metadata":{"id":"i_x8_WQ4nfw6"}},{"cell_type":"code","source":["# Function to process each article and target\n","def process_article(article, target, optimized_prompt):\n","    generated_output = generate_text(optimized_prompt, article)\n","    similarity = compute_similarity(generated_output, target)\n","    return similarity, generated_output"],"metadata":{"id":"zTL9drqOjDX-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if False:\n","  optimized_prompt = base_prompt\n","  best_generated_output = None\n","  NB_JOBS = 3\n","\n","  for iteration in tqdm(range(num_iterations), desc=\"Iterations\"):\n","      # Parallel processing of articles and targets\n","      results = Parallel(n_jobs=NB_JOBS)(delayed(process_article)(article, target, optimized_prompt) for article, target in zip(articles, targets))\n","\n","      # Extract similarities and generated outputs\n","      similarities, generated_outputs = zip(*results)\n","\n","      # Compute the average similarity for this iteration\n","      avg_similarity = np.mean(similarities)\n","      print(f\"Iteration {iteration + 1}/{num_iterations}, Avg Similarity: {avg_similarity:.4f}\")\n","\n","      # Update prompt using the optimizer LLM\n","      if iteration < num_iterations - 1:\n","          best_generated_output = generated_outputs[np.argmax(similarities)]\n","          optimized_prompt = optimize_prompt(optimized_prompt, articles[0], best_generated_output, avg_similarity)\n","\n","  print(\"Final optimized prompt:\", optimized_prompt)"],"metadata":{"id":"-j0S1Lvun9by"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Without parallelization"],"metadata":{"id":"voVpVz8KniO5"}},{"cell_type":"code","source":["# Prompt tuning loop\n","optimized_prompt = base_prompt\n","for iteration in tqdm(range(num_iterations)):\n","    similarities = []\n","\n","    for article, target in tqdm(zip(articles, targets)):\n","        # Generate output using the current prompt\n","        generated_output = generate_text(optimized_prompt, article)\n","\n","        # Compute similarity between generated output and target\n","        similarity = compute_similarity(generated_output, target)\n","        similarities.append(similarity)\n","\n","    # Compute the average similarity for this iteration\n","    avg_similarity = np.mean(similarities)\n","    print(f\"Iteration {iteration + 1}/{num_iterations}, Avg Similarity: {avg_similarity:.4f}\")\n","\n","    # Update prompt using the optimizer LLM\n","    if iteration < num_iterations - 1:\n","        optimized_prompt = optimize_prompt(optimized_prompt, articles[0], generated_output, avg_similarity)\n","\n","print(\"Final optimized prompt:\", optimized_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":651},"id":"-4CzEQrkdiH0","executionInfo":{"status":"error","timestamp":1734086784462,"user_tz":-60,"elapsed":127640,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}},"outputId":"5164e132-6ae8-4f69-d916-d0a5b7495edc"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 1/5, Avg Similarity: 0.5528\n"]},{"output_type":"error","ename":"ValueError","evalue":"Input length of input_ids is 512, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-94eac56ea62d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Update prompt using the optimizer LLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimized_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final optimized prompt:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimized_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-b6566e07c648>\u001b[0m in \u001b[0;36moptimize_prompt\u001b[0;34m(current_prompt, target, output, similarity)\u001b[0m\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2103\u001b[0m             \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_logits_to_keep\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m         \u001b[0;31m# 7. Prepare the cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1412\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 512, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."]}]},{"cell_type":"code","source":["optimized_prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"D1SGR0sliWjY","executionInfo":{"status":"ok","timestamp":1734086840308,"user_tz":-60,"elapsed":250,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}},"outputId":"1a1fe51a-c83a-4a1c-8c7f-efc9ed5f6d16"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Current Prompt: Summarize the following article: \\nTarget: Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\\nWorkers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\\nThe Welsh Government said more people than ever were getting help to address housing problems.\\nChanges to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\\nPrison Link Cymru, which helps people find accommodation after their release, said things were generally good for women because issues such as children or domestic violence were now considered.\\nHowever, the same could not be said for men, the charity said, because issues which often affect them, such as post traumatic stress disorder or drug dependency, were often viewed as less of a priority.\\nAndrew Stevens, who works in Welsh prisons trying to secure housing for prison leavers, said the need for accommodation was \"chronic\".\\n\"There\\'s a desperate need for it, finding suitable accommodation for those leaving prison there is just a lack of it everywhere,\" he said.\\n\"It could take six months to a year, without a lot of help they could be on the streets for six months.\\n\"When you think of the consequences of either being on the street, especially with the cold weather at the moment or you may have a roof over your head, sometimes there is only one choice.\"\\nMr Stevens believes building more one-bedroom flats could help ease the problem.\\n\"The average price is a hundred pounds a week to keep someone in a rented flat, prison is a lot more than that so I would imagine it would save the public purse quite a few pounds,\" he said.\\nOfficial figures show 830 one-bedroom properties were built in the year to March 2016, of an overall total of 6,900 new properties in Wales.\\nMarc, 50, who has been in and out of prison for the past 20 years for burglary offences, said he struggled to find accommodation each time he was released.\\nHe said he would ask himself: \"Where am I going to stay? Where am I going to live? Have I got somewhere where I can see my daughter.\"\\n\"You\\'re put out among the same sort of people doing the same sort of thing, and it\\'s difficult, it\\'s difficult to get away from it. It\\'s like every man\\'s problem.\\n\"I\\'ve seen people come to the streets without really understanding that they\\'re not criminals.\\n\"We need to be very proactive about why people come out and come out of jail. So it\\'s just a natural change in circumstances where our society does have more to spend on housing.\\n\"I\\'m not going to be blaming people.\"'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[],"metadata":{"id":"T3k6KkQSdiJ8","executionInfo":{"status":"aborted","timestamp":1734086433170,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SicUcNhJdiMU","executionInfo":{"status":"aborted","timestamp":1734086433170,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alberto Barbado","userId":"01473263592719413703"}}},"execution_count":null,"outputs":[]}]}